{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stic-lab/AG-037/blob/main/MAGAN_F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhrkM2wF5zmW"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "# import os\n",
        "from os import listdir\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "from numpy.random import randn\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.data import AUTOTUNE\n",
        "from keras.losses import BinaryCrossentropy, MeanSquaredError\n",
        "from keras.layers import Activation, Concatenate,Input, Dense, Reshape, Flatten, Dropout, LeakyReLU, RandomCrop\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D, AveragePooling2D, UpSampling2D, Conv2DTranspose\n",
        "from keras.models import Model, Input,Sequential\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "# import tensorflow as tf\n",
        "from tensorflow import sigmoid, reduce_max, nn, concat, image, shape\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jeUnOPR7omp"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NujP63sc8D0c"
      },
      "outputs": [],
      "source": [
        "image_shape =(256,256,3) #(286, 286)\n",
        "batch_size = 64\n",
        "epochs = 200\n",
        "save_dir = \"./\"\n",
        "path = \"/content/drive/MyDrive/DATA/train/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVQDc0uAqgHa"
      },
      "source": [
        "### Some useful function that could be used to load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7axECkaA9Gqx"
      },
      "outputs": [],
      "source": [
        "trainAug = Sequential([\n",
        "\tpreprocessing.Rescaling(scale=1.0 / 255),\n",
        "\tpreprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "\tpreprocessing.RandomZoom(\n",
        "\t\theight_factor=(-0.05, -0.15),\n",
        "\t\twidth_factor=(-0.05, -0.15)),\n",
        "\tpreprocessing.RandomRotation(0.3)\n",
        "])\n",
        "\n",
        "def load_images(path, size=image_shape):\n",
        "  data_list = list()\n",
        "  # enumerate filenames in directory, assume all are images\n",
        "  for filename in listdir(path):\n",
        "    # load and resize the image\n",
        "    pixels = load_img(path + filename, target_size=size)\n",
        "    # convert to numpy array\n",
        "    pixels = img_to_array(pixels)\n",
        "    # store\n",
        "    data_list.append(pixels)\n",
        "\n",
        "  datas = asarray(data_list)\n",
        "  datas = datas.astype('float32') / 255.0\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(datas)\n",
        "  # dataset = dataset.batch(128)\n",
        "  dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZAk8dtB9HsF"
      },
      "outputs": [],
      "source": [
        "# load dataset (low light image)\n",
        "dataL_all = load_images(path + 'low/')\n",
        "dataG_all = (\n",
        "\tdataL_all\n",
        "\t.shuffle(batch_size * 100)\n",
        "\t# .batch(batch_size)\n",
        "\t.map(lambda x: (trainAug(x)),\n",
        "\t\t num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\t.prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "dataL_all = (\n",
        "\tdataL_all\n",
        "\t.shuffle(batch_size * 100)\n",
        "\t# .batch(batch_size)\n",
        "\t.map(lambda x: (trainAug(x)),\n",
        "\t\t num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\t.prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "# load dataset (normal light image)\n",
        "dataH_all = load_images(path + 'normal/')\n",
        "dataH_all = (\n",
        "\tdataH_all\n",
        "\t.shuffle(batch_size * 100)\n",
        "\t# .batch(batch_size)\n",
        "\t.map(lambda x: (trainAug(x)),\n",
        "\t\t num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\t.prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "# Prepare the training dataset.\n",
        "# train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "# train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wpS9H16BKop"
      },
      "source": [
        "Visualize some samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXT43KI_9Poc"
      },
      "outputs": [],
      "source": [
        "#Displaying images\n",
        "# dataL = dataL_all.take(4)\n",
        "# dataH = dataH_all.take(4)\n",
        "# _, ax = plt.subplots(4, 2, figsize=(10, 15))\n",
        "# print(dataL)\n",
        "# # plt.figure(figsize=(20, 4))\n",
        "# steps = tf.data.Dataset.range(4)\n",
        "# # steps = range(0,4)\n",
        "# i=0;\n",
        "# for L, H in enumerate(zip(dataL, dataH)):\n",
        "#     ax[i, 0].imshow(L)\n",
        "#     ax[i, 1].imshow(H)\n",
        "#     i=i+1\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# _, ax = plt.subplots(4, 2, figsize=(10, 15))\n",
        "# for i, samples in enumerate(zip(dataL_all.take(4), dataH_all.take(4))):\n",
        "#     low = ((samples[0][0] * 255.0).numpy()).astype(np.uint8)\n",
        "#     normal = ((samples[1][0] * 255.0).numpy()).astype(np.uint8)\n",
        "#     ax[i, 0].imshow(low)\n",
        "#     ax[i, 1].imshow(normal)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcz40y4hAcyc",
        "outputId": "aaf81fcd-9f4f-4333-b8a9-f530e65283bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"local_discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " random_crop_3 (RandomCrop)  (None, 28, 28, 3)         0         \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 14, 14, 8)         224       \n",
            "                                                                 \n",
            " leaky_re_lu_240 (LeakyReLU)  (None, 14, 14, 8)        0         \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 7, 7, 16)          1168      \n",
            "                                                                 \n",
            " leaky_re_lu_241 (LeakyReLU)  (None, 7, 7, 16)         0         \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 4, 4, 32)          4640      \n",
            "                                                                 \n",
            " leaky_re_lu_242 (LeakyReLU)  (None, 4, 4, 32)         0         \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 2, 2, 64)          18496     \n",
            "                                                                 \n",
            " leaky_re_lu_243 (LeakyReLU)  (None, 2, 2, 64)         0         \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (None, 1, 1, 128)         73856     \n",
            "                                                                 \n",
            " leaky_re_lu_244 (LeakyReLU)  (None, 1, 1, 128)        0         \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 1, 1, 256)         295168    \n",
            "                                                                 \n",
            " leaky_re_lu_245 (LeakyReLU)  (None, 1, 1, 256)        0         \n",
            "                                                                 \n",
            " global_max_pooling2d_6 (Glo  (None, 256)              0         \n",
            " balMaxPooling2D)                                                \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 393,809\n",
            "Trainable params: 393,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator_local = Sequential(\n",
        "    [\n",
        "        Input(shape=image_shape),\n",
        "        RandomCrop(28, 28),\n",
        "        Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        GlobalMaxPooling2D(),\n",
        "        Dense(1),\n",
        "    ],\n",
        "    name=\"local_discriminator\",\n",
        ")\n",
        "discriminator_local.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTqgihtIL5L6",
        "outputId": "350478ce-8eca-4b69-d278-87f7b6591ff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator_global\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_42 (Conv2D)          (None, 128, 128, 8)       224       \n",
            "                                                                 \n",
            " leaky_re_lu_246 (LeakyReLU)  (None, 128, 128, 8)      0         \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (None, 64, 64, 16)        1168      \n",
            "                                                                 \n",
            " leaky_re_lu_247 (LeakyReLU)  (None, 64, 64, 16)       0         \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 32, 32, 32)        4640      \n",
            "                                                                 \n",
            " leaky_re_lu_248 (LeakyReLU)  (None, 32, 32, 32)       0         \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " leaky_re_lu_249 (LeakyReLU)  (None, 16, 16, 64)       0         \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " leaky_re_lu_250 (LeakyReLU)  (None, 8, 8, 128)        0         \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (None, 4, 4, 512)         590336    \n",
            "                                                                 \n",
            " leaky_re_lu_251 (LeakyReLU)  (None, 4, 4, 512)        0         \n",
            "                                                                 \n",
            " global_max_pooling2d_7 (Glo  (None, 512)              0         \n",
            " balMaxPooling2D)                                                \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 689,233\n",
            "Trainable params: 689,233\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator_global = Sequential(\n",
        "    [\n",
        "        Input(shape=image_shape),\n",
        "        Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        GlobalMaxPooling2D(),\n",
        "        Dense(1),\n",
        "    ],\n",
        "    name=\"discriminator_global\",\n",
        ")\n",
        "discriminator_global.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ikb_j5CopDqc"
      },
      "source": [
        "Feature attention function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUmb1R6ipEUT"
      },
      "outputs": [],
      "source": [
        "def featureAttention(input_feature, idx):\n",
        "  \n",
        "    #Maxpoolin conv sigmoid conv\n",
        "    fa_max = MaxPooling2D(name=\"fa_max\"+idx, pool_size=(input_feature[0].shape[0], input_feature[0].shape[1]), strides=1, padding='valid')(input_feature)\n",
        "    fa_conv_max = Conv2D(name=\"fa_conv_max\"+idx,filters=input_feature[0].shape[2],kernel_size=3, padding='same', activation=LeakyReLU())(fa_max)\n",
        "    fa_sigmoid_max = sigmoid(fa_conv_max)\n",
        "    fa_conv_sigmoid_max = Conv2D(name=\"fa_conv_sigmoid_max\"+idx, filters=input_feature[0].shape[2],kernel_size=3, padding='same', activation=LeakyReLU())(fa_sigmoid_max)\n",
        "    #Average conv sigmoid conv\n",
        "    fa_avg = AveragePooling2D(name=\"fa_avg\"+idx, pool_size=(input_feature[0].shape[0], input_feature[1].shape[1]), strides=1, padding='valid')(input_feature)\n",
        "    fa_conv_avg = Conv2D(name=\"fa_conv_avg\"+idx, filters=input_feature[0].shape[2],kernel_size=3, padding='same', activation=LeakyReLU())(fa_avg)\n",
        "    fa_sigmoid_avg = sigmoid(fa_conv_avg)\n",
        "    fa_conv_sigmoid_avg = Conv2D(name=\"fa_conv_sigmoid_avg\"+idx, filters=input_feature[0].shape[2],kernel_size=3, padding='same', activation=LeakyReLU())(fa_sigmoid_avg)\n",
        "    #add the result of the two last conv from the max and avg pool and perform sigmoid on it\n",
        "    sum_conv_max_avg = sigmoid(fa_conv_sigmoid_max+fa_conv_sigmoid_avg)\n",
        "    return sum_conv_max_avg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ky7Rf0mp3r7"
      },
      "source": [
        "Pixel attention function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03JzIDWsQx_u"
      },
      "outputs": [],
      "source": [
        "def mixedAttention(input_feature, idx):\n",
        "  featureAtt = featureAttention(input_feature,idx)\n",
        "  intermediate = input_feature * featureAtt\n",
        "  #Maxpoolin conv sigmoid conv\n",
        "  pa_max = MaxPooling2D(name=\"pa_max\"+idx, pool_size=(1,input_feature[0].shape[2]), strides=1, padding='same')(intermediate)\n",
        "  pa_conv_max = Conv2D(name=\"pa_conv_max\"+idx, filters=1, kernel_size=1, padding='valid', activation=LeakyReLU())(pa_max)\n",
        "    #Average conv sigmoid conv\n",
        "  pa_avg = AveragePooling2D(name=\"pa_avg\"+idx, pool_size=(1, input_feature[0].shape[2]), strides=1, padding='same')(intermediate)\n",
        "  pa_conv_avg = Conv2D(name=\"pa_conv_avg\"+idx, filters=1, kernel_size=1, padding='valid', activation=LeakyReLU())(pa_avg)\n",
        "    #Concatenation\n",
        "  pa_concat = concat(name=\"pa_conv_concat\"+idx, values=[pa_conv_max,pa_conv_avg], axis=3)\n",
        "    \n",
        "  pa_conv_concat = Conv2D(name=\"pa_conv_concat\"+idx, filters=input_feature[0].shape[2], kernel_size=3, padding='same', activation=LeakyReLU())(pa_concat)\n",
        "  #add the result of the two last conv from the max and avg pool and perform sigmoid on it\n",
        "  sum_conv_max_concat = sigmoid(pa_conv_concat)\n",
        "  pixelAtt = input_feature * sum_conv_max_concat\n",
        "  return pixelAtt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p7eMlZayjWC"
      },
      "source": [
        "Define the Generative part (Auto encoder network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8lcNE8sydqF",
        "outputId": "adee6af4-2196-44c9-f497-fb04ef804d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Generator_auto_encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_image (InputLayer)       [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv01 (Conv2D)                (None, 256, 256, 8)  6152        ['input_image[0][0]']            \n",
            "                                                                                                  \n",
            " fa_max0 (MaxPooling2D)         (None, 1, 1, 8)      0           ['conv01[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_avg0 (AveragePooling2D)     (None, 1, 1, 8)      0           ['conv01[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_conv_max0 (Conv2D)          (None, 1, 1, 8)      584         ['fa_max0[0][0]']                \n",
            "                                                                                                  \n",
            " fa_conv_avg0 (Conv2D)          (None, 1, 1, 8)      584         ['fa_avg0[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_93 (TFOpLambda  (None, 1, 1, 8)     0           ['fa_conv_max0[0][0]']           \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_94 (TFOpLambda  (None, 1, 1, 8)     0           ['fa_conv_avg0[0][0]']           \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " fa_conv_sigmoid_max0 (Conv2D)  (None, 1, 1, 8)      584         ['tf.math.sigmoid_93[0][0]']     \n",
            "                                                                                                  \n",
            " fa_conv_sigmoid_avg0 (Conv2D)  (None, 1, 1, 8)      584         ['tf.math.sigmoid_94[0][0]']     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_27 (TFOpL  (None, 1, 1, 8)     0           ['fa_conv_sigmoid_max0[0][0]',   \n",
            " ambda)                                                           'fa_conv_sigmoid_avg0[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_95 (TFOpLambda  (None, 1, 1, 8)     0           ['tf.__operators__.add_27[0][0]']\n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_39 (TFOpLambd  (None, 256, 256, 8)  0          ['tf.math.sigmoid_95[0][0]',     \n",
            " a)                                                               'conv01[0][0]']                 \n",
            "                                                                                                  \n",
            " conv02 (Conv2D)                (None, 256, 256, 8)  584         ['tf.math.multiply_39[0][0]']    \n",
            "                                                                                                  \n",
            " max_pool01 (MaxPooling2D)      (None, 128, 128, 8)  0           ['conv02[0][0]']                 \n",
            "                                                                                                  \n",
            " conv03 (Conv2D)                (None, 128, 128, 16  1168        ['max_pool01[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv04 (Conv2D)                (None, 128, 128, 16  2320        ['conv03[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " fa_max1 (MaxPooling2D)         (None, 1, 1, 16)     0           ['conv04[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_avg1 (AveragePooling2D)     (None, 1, 1, 16)     0           ['conv04[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_conv_max1 (Conv2D)          (None, 1, 1, 16)     2320        ['fa_max1[0][0]']                \n",
            "                                                                                                  \n",
            " fa_conv_avg1 (Conv2D)          (None, 1, 1, 16)     2320        ['fa_avg1[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_96 (TFOpLambda  (None, 1, 1, 16)    0           ['fa_conv_max1[0][0]']           \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_97 (TFOpLambda  (None, 1, 1, 16)    0           ['fa_conv_avg1[0][0]']           \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " fa_conv_sigmoid_max1 (Conv2D)  (None, 1, 1, 16)     2320        ['tf.math.sigmoid_96[0][0]']     \n",
            "                                                                                                  \n",
            " fa_conv_sigmoid_avg1 (Conv2D)  (None, 1, 1, 16)     2320        ['tf.math.sigmoid_97[0][0]']     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_28 (TFOpL  (None, 1, 1, 16)    0           ['fa_conv_sigmoid_max1[0][0]',   \n",
            " ambda)                                                           'fa_conv_sigmoid_avg1[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_98 (TFOpLambda  (None, 1, 1, 16)    0           ['tf.__operators__.add_28[0][0]']\n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_40 (TFOpLambd  (None, 128, 128, 16  0          ['conv04[0][0]',                 \n",
            " a)                             )                                 'tf.math.sigmoid_98[0][0]']     \n",
            "                                                                                                  \n",
            " pa_max1 (MaxPooling2D)         (None, 128, 128, 16  0           ['tf.math.multiply_40[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pa_avg1 (AveragePooling2D)     (None, 128, 128, 16  0           ['tf.math.multiply_40[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pa_conv_max1 (Conv2D)          (None, 128, 128, 1)  17          ['pa_max1[0][0]']                \n",
            "                                                                                                  \n",
            " pa_conv_avg1 (Conv2D)          (None, 128, 128, 1)  17          ['pa_avg1[0][0]']                \n",
            "                                                                                                  \n",
            " tf.concat_12 (TFOpLambda)      (None, 128, 128, 2)  0           ['pa_conv_max1[0][0]',           \n",
            "                                                                  'pa_conv_avg1[0][0]']           \n",
            "                                                                                                  \n",
            " pa_conv_concat1 (Conv2D)       (None, 128, 128, 16  304         ['tf.concat_12[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_99 (TFOpLambda  (None, 128, 128, 16  0          ['pa_conv_concat1[0][0]']        \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_41 (TFOpLambd  (None, 128, 128, 16  0          ['conv04[0][0]',                 \n",
            " a)                             )                                 'tf.math.sigmoid_99[0][0]']     \n",
            "                                                                                                  \n",
            " max_pool02 (MaxPooling2D)      (None, 64, 64, 16)   0           ['tf.math.multiply_41[0][0]']    \n",
            "                                                                                                  \n",
            " conv05 (Conv2D)                (None, 64, 64, 32)   4640        ['max_pool02[0][0]']             \n",
            "                                                                                                  \n",
            " conv06 (Conv2D)                (None, 64, 64, 32)   9248        ['conv05[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_max2 (MaxPooling2D)         (None, 1, 1, 32)     0           ['conv06[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_avg2 (AveragePooling2D)     (None, 1, 1, 32)     0           ['conv06[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_conv_max2 (Conv2D)          (None, 1, 1, 32)     9248        ['fa_max2[0][0]']                \n",
            "                                                                                                  \n",
            " fa_conv_avg2 (Conv2D)          (None, 1, 1, 32)     9248        ['fa_avg2[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_100 (TFOpLambd  (None, 1, 1, 32)    0           ['fa_conv_max2[0][0]']           \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_101 (TFOpLambd  (None, 1, 1, 32)    0           ['fa_conv_avg2[0][0]']           \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " fa_conv_sigmoid_max2 (Conv2D)  (None, 1, 1, 32)     9248        ['tf.math.sigmoid_100[0][0]']    \n",
            "                                                                                                  \n",
            " fa_conv_sigmoid_avg2 (Conv2D)  (None, 1, 1, 32)     9248        ['tf.math.sigmoid_101[0][0]']    \n",
            "                                                                                                  \n",
            " tf.__operators__.add_29 (TFOpL  (None, 1, 1, 32)    0           ['fa_conv_sigmoid_max2[0][0]',   \n",
            " ambda)                                                           'fa_conv_sigmoid_avg2[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_102 (TFOpLambd  (None, 1, 1, 32)    0           ['tf.__operators__.add_29[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_42 (TFOpLambd  (None, 64, 64, 32)  0           ['conv06[0][0]',                 \n",
            " a)                                                               'tf.math.sigmoid_102[0][0]']    \n",
            "                                                                                                  \n",
            " pa_max2 (MaxPooling2D)         (None, 64, 64, 32)   0           ['tf.math.multiply_42[0][0]']    \n",
            "                                                                                                  \n",
            " pa_avg2 (AveragePooling2D)     (None, 64, 64, 32)   0           ['tf.math.multiply_42[0][0]']    \n",
            "                                                                                                  \n",
            " pa_conv_max2 (Conv2D)          (None, 64, 64, 1)    33          ['pa_max2[0][0]']                \n",
            "                                                                                                  \n",
            " pa_conv_avg2 (Conv2D)          (None, 64, 64, 1)    33          ['pa_avg2[0][0]']                \n",
            "                                                                                                  \n",
            " tf.concat_13 (TFOpLambda)      (None, 64, 64, 2)    0           ['pa_conv_max2[0][0]',           \n",
            "                                                                  'pa_conv_avg2[0][0]']           \n",
            "                                                                                                  \n",
            " pa_conv_concat2 (Conv2D)       (None, 64, 64, 32)   608         ['tf.concat_13[0][0]']           \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_103 (TFOpLambd  (None, 64, 64, 32)  0           ['pa_conv_concat2[0][0]']        \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_43 (TFOpLambd  (None, 64, 64, 32)  0           ['conv06[0][0]',                 \n",
            " a)                                                               'tf.math.sigmoid_103[0][0]']    \n",
            "                                                                                                  \n",
            " max_pool03 (MaxPooling2D)      (None, 32, 32, 32)   0           ['tf.math.multiply_43[0][0]']    \n",
            "                                                                                                  \n",
            " conv07 (Conv2D)                (None, 32, 32, 64)   18496       ['max_pool03[0][0]']             \n",
            "                                                                                                  \n",
            " conv08 (Conv2D)                (None, 32, 32, 64)   36928       ['conv07[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_max3 (MaxPooling2D)         (None, 1, 1, 64)     0           ['conv08[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_avg3 (AveragePooling2D)     (None, 1, 1, 64)     0           ['conv08[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_conv_max3 (Conv2D)          (None, 1, 1, 64)     36928       ['fa_max3[0][0]']                \n",
            "                                                                                                  \n",
            " fa_conv_avg3 (Conv2D)          (None, 1, 1, 64)     36928       ['fa_avg3[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_104 (TFOpLambd  (None, 1, 1, 64)    0           ['fa_conv_max3[0][0]']           \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_105 (TFOpLambd  (None, 1, 1, 64)    0           ['fa_conv_avg3[0][0]']           \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " fa_conv_sigmoid_max3 (Conv2D)  (None, 1, 1, 64)     36928       ['tf.math.sigmoid_104[0][0]']    \n",
            "                                                                                                  \n",
            " fa_conv_sigmoid_avg3 (Conv2D)  (None, 1, 1, 64)     36928       ['tf.math.sigmoid_105[0][0]']    \n",
            "                                                                                                  \n",
            " tf.__operators__.add_30 (TFOpL  (None, 1, 1, 64)    0           ['fa_conv_sigmoid_max3[0][0]',   \n",
            " ambda)                                                           'fa_conv_sigmoid_avg3[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_106 (TFOpLambd  (None, 1, 1, 64)    0           ['tf.__operators__.add_30[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_44 (TFOpLambd  (None, 32, 32, 64)  0           ['conv08[0][0]',                 \n",
            " a)                                                               'tf.math.sigmoid_106[0][0]']    \n",
            "                                                                                                  \n",
            " pa_max3 (MaxPooling2D)         (None, 32, 32, 64)   0           ['tf.math.multiply_44[0][0]']    \n",
            "                                                                                                  \n",
            " pa_avg3 (AveragePooling2D)     (None, 32, 32, 64)   0           ['tf.math.multiply_44[0][0]']    \n",
            "                                                                                                  \n",
            " pa_conv_max3 (Conv2D)          (None, 32, 32, 1)    65          ['pa_max3[0][0]']                \n",
            "                                                                                                  \n",
            " pa_conv_avg3 (Conv2D)          (None, 32, 32, 1)    65          ['pa_avg3[0][0]']                \n",
            "                                                                                                  \n",
            " tf.concat_14 (TFOpLambda)      (None, 32, 32, 2)    0           ['pa_conv_max3[0][0]',           \n",
            "                                                                  'pa_conv_avg3[0][0]']           \n",
            "                                                                                                  \n",
            " pa_conv_concat3 (Conv2D)       (None, 32, 32, 64)   1216        ['tf.concat_14[0][0]']           \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_107 (TFOpLambd  (None, 32, 32, 64)  0           ['pa_conv_concat3[0][0]']        \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_45 (TFOpLambd  (None, 32, 32, 64)  0           ['conv08[0][0]',                 \n",
            " a)                                                               'tf.math.sigmoid_107[0][0]']    \n",
            "                                                                                                  \n",
            " max_pool04 (MaxPooling2D)      (None, 16, 16, 64)   0           ['tf.math.multiply_45[0][0]']    \n",
            "                                                                                                  \n",
            " conv09 (Conv2D)                (None, 16, 16, 128)  73856       ['max_pool04[0][0]']             \n",
            "                                                                                                  \n",
            " conv10 (Conv2D)                (None, 16, 16, 128)  147584      ['conv09[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_max4 (MaxPooling2D)         (None, 1, 1, 128)    0           ['conv10[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_avg4 (AveragePooling2D)     (None, 1, 1, 128)    0           ['conv10[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_conv_max4 (Conv2D)          (None, 1, 1, 128)    147584      ['fa_max4[0][0]']                \n",
            "                                                                                                  \n",
            " fa_conv_avg4 (Conv2D)          (None, 1, 1, 128)    147584      ['fa_avg4[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_108 (TFOpLambd  (None, 1, 1, 128)   0           ['fa_conv_max4[0][0]']           \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_109 (TFOpLambd  (None, 1, 1, 128)   0           ['fa_conv_avg4[0][0]']           \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " fa_conv_sigmoid_max4 (Conv2D)  (None, 1, 1, 128)    147584      ['tf.math.sigmoid_108[0][0]']    \n",
            "                                                                                                  \n",
            " fa_conv_sigmoid_avg4 (Conv2D)  (None, 1, 1, 128)    147584      ['tf.math.sigmoid_109[0][0]']    \n",
            "                                                                                                  \n",
            " tf.__operators__.add_31 (TFOpL  (None, 1, 1, 128)   0           ['fa_conv_sigmoid_max4[0][0]',   \n",
            " ambda)                                                           'fa_conv_sigmoid_avg4[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_110 (TFOpLambd  (None, 1, 1, 128)   0           ['tf.__operators__.add_31[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_46 (TFOpLambd  (None, 16, 16, 128)  0          ['conv10[0][0]',                 \n",
            " a)                                                               'tf.math.sigmoid_110[0][0]']    \n",
            "                                                                                                  \n",
            " pa_max4 (MaxPooling2D)         (None, 16, 16, 128)  0           ['tf.math.multiply_46[0][0]']    \n",
            "                                                                                                  \n",
            " pa_avg4 (AveragePooling2D)     (None, 16, 16, 128)  0           ['tf.math.multiply_46[0][0]']    \n",
            "                                                                                                  \n",
            " pa_conv_max4 (Conv2D)          (None, 16, 16, 1)    129         ['pa_max4[0][0]']                \n",
            "                                                                                                  \n",
            " pa_conv_avg4 (Conv2D)          (None, 16, 16, 1)    129         ['pa_avg4[0][0]']                \n",
            "                                                                                                  \n",
            " tf.concat_15 (TFOpLambda)      (None, 16, 16, 2)    0           ['pa_conv_max4[0][0]',           \n",
            "                                                                  'pa_conv_avg4[0][0]']           \n",
            "                                                                                                  \n",
            " pa_conv_concat4 (Conv2D)       (None, 16, 16, 128)  2432        ['tf.concat_15[0][0]']           \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_111 (TFOpLambd  (None, 16, 16, 128)  0          ['pa_conv_concat4[0][0]']        \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_47 (TFOpLambd  (None, 16, 16, 128)  0          ['conv10[0][0]',                 \n",
            " a)                                                               'tf.math.sigmoid_111[0][0]']    \n",
            "                                                                                                  \n",
            " conv11 (Conv2D)                (None, 16, 16, 128)  147584      ['tf.math.multiply_47[0][0]']    \n",
            "                                                                                                  \n",
            " conv12 (Conv2D)                (None, 16, 16, 128)  147584      ['conv11[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate01 (Concatenate)    (None, 16, 16, 256)  0           ['tf.math.multiply_47[0][0]',    \n",
            "                                                                  'conv12[0][0]']                 \n",
            "                                                                                                  \n",
            " upsampling1 (UpSampling2D)     (None, 32, 32, 256)  0           ['concatenate01[0][0]']          \n",
            "                                                                                                  \n",
            " conv13 (Conv2D)                (None, 32, 32, 64)   4194368     ['upsampling1[0][0]']            \n",
            "                                                                                                  \n",
            " fa_max5 (MaxPooling2D)         (None, 1, 1, 64)     0           ['conv13[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_avg5 (AveragePooling2D)     (None, 1, 1, 64)     0           ['conv13[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_conv_max5 (Conv2D)          (None, 1, 1, 64)     36928       ['fa_max5[0][0]']                \n",
            "                                                                                                  \n",
            " fa_conv_avg5 (Conv2D)          (None, 1, 1, 64)     36928       ['fa_avg5[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_112 (TFOpLambd  (None, 1, 1, 64)    0           ['fa_conv_max5[0][0]']           \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_113 (TFOpLambd  (None, 1, 1, 64)    0           ['fa_conv_avg5[0][0]']           \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " fa_conv_sigmoid_max5 (Conv2D)  (None, 1, 1, 64)     36928       ['tf.math.sigmoid_112[0][0]']    \n",
            "                                                                                                  \n",
            " fa_conv_sigmoid_avg5 (Conv2D)  (None, 1, 1, 64)     36928       ['tf.math.sigmoid_113[0][0]']    \n",
            "                                                                                                  \n",
            " tf.__operators__.add_32 (TFOpL  (None, 1, 1, 64)    0           ['fa_conv_sigmoid_max5[0][0]',   \n",
            " ambda)                                                           'fa_conv_sigmoid_avg5[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_114 (TFOpLambd  (None, 1, 1, 64)    0           ['tf.__operators__.add_32[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_48 (TFOpLambd  (None, 32, 32, 64)  0           ['tf.math.sigmoid_114[0][0]',    \n",
            " a)                                                               'conv13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv14 (Conv2D)                (None, 32, 32, 64)   36928       ['tf.math.multiply_48[0][0]']    \n",
            "                                                                                                  \n",
            " concatenate02 (Concatenate)    (None, 32, 32, 128)  0           ['tf.math.multiply_45[0][0]',    \n",
            "                                                                  'conv14[0][0]']                 \n",
            "                                                                                                  \n",
            " upsampling2 (UpSampling2D)     (None, 64, 64, 128)  0           ['concatenate02[0][0]']          \n",
            "                                                                                                  \n",
            " conv15 (Conv2D)                (None, 64, 64, 32)   1048608     ['upsampling2[0][0]']            \n",
            "                                                                                                  \n",
            " fa_max6 (MaxPooling2D)         (None, 1, 1, 32)     0           ['conv15[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_avg6 (AveragePooling2D)     (None, 1, 1, 32)     0           ['conv15[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_conv_max6 (Conv2D)          (None, 1, 1, 32)     9248        ['fa_max6[0][0]']                \n",
            "                                                                                                  \n",
            " fa_conv_avg6 (Conv2D)          (None, 1, 1, 32)     9248        ['fa_avg6[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_115 (TFOpLambd  (None, 1, 1, 32)    0           ['fa_conv_max6[0][0]']           \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_116 (TFOpLambd  (None, 1, 1, 32)    0           ['fa_conv_avg6[0][0]']           \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " fa_conv_sigmoid_max6 (Conv2D)  (None, 1, 1, 32)     9248        ['tf.math.sigmoid_115[0][0]']    \n",
            "                                                                                                  \n",
            " fa_conv_sigmoid_avg6 (Conv2D)  (None, 1, 1, 32)     9248        ['tf.math.sigmoid_116[0][0]']    \n",
            "                                                                                                  \n",
            " tf.__operators__.add_33 (TFOpL  (None, 1, 1, 32)    0           ['fa_conv_sigmoid_max6[0][0]',   \n",
            " ambda)                                                           'fa_conv_sigmoid_avg6[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_117 (TFOpLambd  (None, 1, 1, 32)    0           ['tf.__operators__.add_33[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_49 (TFOpLambd  (None, 64, 64, 32)  0           ['tf.math.sigmoid_117[0][0]',    \n",
            " a)                                                               'conv15[0][0]']                 \n",
            "                                                                                                  \n",
            " conv16 (Conv2D)                (None, 64, 64, 32)   9248        ['tf.math.multiply_49[0][0]']    \n",
            "                                                                                                  \n",
            " concatenate03 (Concatenate)    (None, 64, 64, 64)   0           ['tf.math.multiply_43[0][0]',    \n",
            "                                                                  'conv16[0][0]']                 \n",
            "                                                                                                  \n",
            " upsampling3 (UpSampling2D)     (None, 128, 128, 64  0           ['concatenate03[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv17 (Conv2D)                (None, 128, 128, 16  262160      ['upsampling3[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " fa_max7 (MaxPooling2D)         (None, 1, 1, 16)     0           ['conv17[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_avg7 (AveragePooling2D)     (None, 1, 1, 16)     0           ['conv17[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_conv_max7 (Conv2D)          (None, 1, 1, 16)     2320        ['fa_max7[0][0]']                \n",
            "                                                                                                  \n",
            " fa_conv_avg7 (Conv2D)          (None, 1, 1, 16)     2320        ['fa_avg7[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_118 (TFOpLambd  (None, 1, 1, 16)    0           ['fa_conv_max7[0][0]']           \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_119 (TFOpLambd  (None, 1, 1, 16)    0           ['fa_conv_avg7[0][0]']           \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " fa_conv_sigmoid_max7 (Conv2D)  (None, 1, 1, 16)     2320        ['tf.math.sigmoid_118[0][0]']    \n",
            "                                                                                                  \n",
            " fa_conv_sigmoid_avg7 (Conv2D)  (None, 1, 1, 16)     2320        ['tf.math.sigmoid_119[0][0]']    \n",
            "                                                                                                  \n",
            " tf.__operators__.add_34 (TFOpL  (None, 1, 1, 16)    0           ['fa_conv_sigmoid_max7[0][0]',   \n",
            " ambda)                                                           'fa_conv_sigmoid_avg7[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_120 (TFOpLambd  (None, 1, 1, 16)    0           ['tf.__operators__.add_34[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_50 (TFOpLambd  (None, 128, 128, 16  0          ['tf.math.sigmoid_120[0][0]',    \n",
            " a)                             )                                 'conv17[0][0]']                 \n",
            "                                                                                                  \n",
            " conv18 (Conv2D)                (None, 128, 128, 16  2320        ['tf.math.multiply_50[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate04 (Concatenate)    (None, 128, 128, 32  0           ['tf.math.multiply_41[0][0]',    \n",
            "                                )                                 'conv18[0][0]']                 \n",
            "                                                                                                  \n",
            " upsampling4 (UpSampling2D)     (None, 256, 256, 32  0           ['concatenate04[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv19 (Conv2D)                (None, 256, 256, 8)  65544       ['upsampling4[0][0]']            \n",
            "                                                                                                  \n",
            " fa_max8 (MaxPooling2D)         (None, 1, 1, 8)      0           ['conv19[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_avg8 (AveragePooling2D)     (None, 1, 1, 8)      0           ['conv19[0][0]']                 \n",
            "                                                                                                  \n",
            " fa_conv_max8 (Conv2D)          (None, 1, 1, 8)      584         ['fa_max8[0][0]']                \n",
            "                                                                                                  \n",
            " fa_conv_avg8 (Conv2D)          (None, 1, 1, 8)      584         ['fa_avg8[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_121 (TFOpLambd  (None, 1, 1, 8)     0           ['fa_conv_max8[0][0]']           \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_122 (TFOpLambd  (None, 1, 1, 8)     0           ['fa_conv_avg8[0][0]']           \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " fa_conv_sigmoid_max8 (Conv2D)  (None, 1, 1, 8)      584         ['tf.math.sigmoid_121[0][0]']    \n",
            "                                                                                                  \n",
            " fa_conv_sigmoid_avg8 (Conv2D)  (None, 1, 1, 8)      584         ['tf.math.sigmoid_122[0][0]']    \n",
            "                                                                                                  \n",
            " tf.__operators__.add_35 (TFOpL  (None, 1, 1, 8)     0           ['fa_conv_sigmoid_max8[0][0]',   \n",
            " ambda)                                                           'fa_conv_sigmoid_avg8[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_123 (TFOpLambd  (None, 1, 1, 8)     0           ['tf.__operators__.add_35[0][0]']\n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_51 (TFOpLambd  (None, 256, 256, 8)  0          ['tf.math.sigmoid_123[0][0]',    \n",
            " a)                                                               'conv19[0][0]']                 \n",
            "                                                                                                  \n",
            " conv20 (Conv2D)                (None, 256, 256, 8)  584         ['tf.math.multiply_51[0][0]']    \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 256, 256, 16  0           ['conv02[0][0]',                 \n",
            "                                )                                 'conv20[0][0]']                 \n",
            "                                                                                                  \n",
            " conv21 (Conv2D)                (None, 256, 256, 3)  435         ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 256, 256, 3)  0           ['input_image[0][0]',            \n",
            "                                                                  'conv21[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,204,363\n",
            "Trainable params: 7,204,363\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "def Generator():\n",
        "  \n",
        "    ###############*******************************#################\n",
        "    inputs = Input(name=\"input_image\", shape=image_shape)\n",
        "    conv01 = Conv2D(name=\"conv01\", filters=8,kernel_size=16, padding='same', activation=LeakyReLU(alpha=0.2))(inputs)\n",
        "    ##################################\n",
        "    #Start the first feature attention\n",
        "    feat0 = featureAttention(input_feature=conv01, idx=\"0\")\n",
        "    out_feature0 = feat0*conv01\n",
        "    # End feature attention\n",
        "    ##################################\n",
        "    conv02 = Conv2D(name=\"conv02\", filters=8,kernel_size=3, padding='same', activation=LeakyReLU())(out_feature0)\n",
        "    max_pool01 = MaxPooling2D(name=\"max_pool01\", pool_size=(3, 3), strides=2, padding='same')(conv02)\n",
        "    ###############*******************************#################\n",
        "    \n",
        "    ###############*******************************#################\n",
        "    conv03 = Conv2D(name=\"conv03\", filters=16,kernel_size=3, padding='same', activation=LeakyReLU())(max_pool01)\n",
        "    conv04 = Conv2D(name=\"conv04\", filters=16,kernel_size=3, padding='same', activation=LeakyReLU())(conv03)\n",
        "    ##################################\n",
        "    mixed_att_01 = mixedAttention(input_feature=conv04, idx=\"1\")\n",
        "    ##################################\n",
        "    max_pool02 = MaxPooling2D(name=\"max_pool02\", pool_size=(3, 3), strides=2, padding='same')(mixed_att_01)\n",
        "    ###############*******************************#################\n",
        "\n",
        "    \n",
        "    ###############*******************************#################\n",
        "    conv05 = Conv2D(name=\"conv05\", filters=32,kernel_size=3, padding='same', activation=LeakyReLU())(max_pool02)\n",
        "    conv06 = Conv2D(name=\"conv06\", filters=32,kernel_size=3, padding='same', activation=LeakyReLU())(conv05)\n",
        "    mixed_att_02 = mixedAttention(input_feature=conv06, idx=\"2\")\n",
        "    max_pool03 = MaxPooling2D(name=\"max_pool03\", pool_size=(3, 3), strides=2, padding='same')(mixed_att_02)\n",
        "    ###############*******************************#################\n",
        "\n",
        "    ###############*******************************#################\n",
        "    conv07 = Conv2D(name=\"conv07\", filters=64,kernel_size=3, padding='same', activation=LeakyReLU())(max_pool03)\n",
        "    conv08 = Conv2D(name=\"conv08\", filters=64,kernel_size=3, padding='same', activation=LeakyReLU())(conv07)\n",
        "    mixed_att_03 = mixedAttention(input_feature=conv08, idx=\"3\")\n",
        "    max_pool04 = MaxPooling2D(name=\"max_pool04\", pool_size=(3, 3), strides=2, padding='same')(mixed_att_03)\n",
        "    ###############*******************************#################\n",
        "    \n",
        "    \n",
        "    ###############*******************************#################\n",
        "    conv09 = Conv2D(name=\"conv09\", filters=128,kernel_size=3, padding='same', activation=LeakyReLU())(max_pool04)\n",
        "    conv10 = Conv2D(name=\"conv10\", filters=128,kernel_size=3, padding='same', activation=LeakyReLU())(conv09)\n",
        "        ##################################\n",
        "    mixed_att_04 = mixedAttention(input_feature=conv10, idx=\"4\")\n",
        "    ##################################\n",
        "    ###############*******************************#################\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ###############*******************************#################\n",
        "    conv11 = Conv2D(name=\"conv11\", filters=128,kernel_size=3, padding='same', activation=LeakyReLU())(mixed_att_04)\n",
        "    conv12 = Conv2D(name=\"conv12\", filters=128,kernel_size=3, padding='same', activation=LeakyReLU())(conv11)\n",
        "    concat01 = tf.keras.layers.Concatenate(name=\"concatenate01\", axis=3)([mixed_att_04, conv12])\n",
        "    upsampling1 = UpSampling2D(name=\"upsampling1\", size=(2, 2))(concat01)\n",
        "    ###############*******************************#################\n",
        "    \n",
        "    ###############*******************************#################\n",
        "    conv13 = Conv2D(name=\"conv13\", filters=64,kernel_size=16, padding='same', activation=LeakyReLU())(upsampling1)\n",
        "    ##################################\n",
        "    #Start the first feature attention\n",
        "    feat5 = featureAttention(input_feature=conv13, idx=\"5\")\n",
        "    out_feature5 = feat5*conv13\n",
        "    # End feature attention\n",
        "    ##################################\n",
        "    conv14 = Conv2D(name=\"conv14\", filters=64,kernel_size=3, padding='same', activation=LeakyReLU())(out_feature5)\n",
        "    concat02 = tf.keras.layers.Concatenate(name=\"concatenate02\", axis=3)([mixed_att_03, conv14])\n",
        "    upsampling2 = UpSampling2D(name=\"upsampling2\", size=(2, 2))(concat02)\n",
        "    ###############*******************************#################\n",
        "    \n",
        "    ###############*******************************#################\n",
        "    conv15 = Conv2D(name=\"conv15\", filters=32,kernel_size=16, padding='same', activation=LeakyReLU())(upsampling2)\n",
        "    ##################################\n",
        "    #Start the first feature attention\n",
        "    feat6 = featureAttention(input_feature=conv15, idx=\"6\")\n",
        "    out_feature6 = feat6*conv15\n",
        "    # End feature attention\n",
        "    ##################################\n",
        "    conv16 = Conv2D(name=\"conv16\", filters=32,kernel_size=3, padding='same', activation=LeakyReLU())(out_feature6)\n",
        "    concat03 = tf.keras.layers.Concatenate(name=\"concatenate03\", axis=3)([mixed_att_02, conv16])\n",
        "    upsampling3 = UpSampling2D(name=\"upsampling3\", size=(2, 2))(concat03)\n",
        "    ###############*******************************#################\n",
        "\n",
        "    \n",
        "    ###############*******************************#################\n",
        "    conv17 = Conv2D(name=\"conv17\", filters=16,kernel_size=16, padding='same', activation=LeakyReLU())(upsampling3)\n",
        "    ##################################\n",
        "    #Start the first feature attention\n",
        "    feat7 = featureAttention(input_feature=conv17, idx=\"7\")\n",
        "    out_feature7 = feat7*conv17\n",
        "    # End feature attention\n",
        "    ##################################\n",
        "    conv18 = Conv2D(name=\"conv18\", filters=16,kernel_size=3, padding='same', activation=LeakyReLU())(out_feature7)\n",
        "    concat04 = tf.keras.layers.Concatenate(name=\"concatenate04\", axis=3)([mixed_att_01, conv18])\n",
        "    upsampling4 = UpSampling2D(name=\"upsampling4\", size=(2, 2))(concat04)\n",
        "    ###############*******************************#################\n",
        "\n",
        "    \n",
        "    ###############*******************************#################\n",
        "    conv19 = Conv2D(name=\"conv19\", filters=8,kernel_size=16, padding='same', activation=LeakyReLU())(upsampling4)\n",
        "    ##################################\n",
        "    #Start the first feature attention\n",
        "    feat8 = featureAttention(input_feature=conv19, idx=\"8\")\n",
        "    out_feature8 = feat8*conv19\n",
        "    # End feature attention\n",
        "    ##################################\n",
        "    conv20 = Conv2D(name=\"conv20\", filters=8,kernel_size=3, padding='same', activation=LeakyReLU())(out_feature8)\n",
        "    concat01 = tf.keras.layers.Concatenate(axis=3)([conv02, conv20])\n",
        "\n",
        "    conv21 = Conv2D(name=\"conv21\", filters=3,kernel_size=3, padding='same')(concat01)\n",
        "    ###############*******************************#################\n",
        "    output = tf.keras.layers.Add()([inputs, conv21])\n",
        "\n",
        "\n",
        "    model = Model(inputs, output)\n",
        "    # opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "    model._name=\"Generator_auto_encoder\"\n",
        "    # model.compile(loss=['mae', 'mae'], optimizer=opt, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "generator = Generator()\n",
        "print(generator.summary())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gram_matrix(input_tensor):\n",
        "  result = tf.linag.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
        "  gram_matrix = tf.expand_dims(result, axis=0)\n",
        "  input_shape = tf.shape(input_tensor)\n",
        "  i_j = tf.cast(input_shape[1]*input_shape[2], tf.float32)\n",
        "  return gram_matrix/i_j"
      ],
      "metadata": {
        "id": "ExP3qkgSFHf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_vgg():\n",
        "  vgg = tf.keras.applications.VGG9(include_top=True, weights=\"imagenet\")\n",
        "  vgg.trainable = False\n",
        "  content_layers = ['block4_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1','block4_conv1','block5_conv1']\n",
        "  content_output = vgg.get_layer(content_layers[0]).output\n",
        "  style_output = [vgg.get_layer(style_layer).output for style_layer in style_layers]\n",
        "  gram_style_output = [gram_matrix(output_) for output_ in style_output]\n",
        "  \n",
        "  model = Model([vgg.input], [content_output, gram_style_output])\n",
        "  return model"
      ],
      "metadata": {
        "id": "VeV_UGABFJKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_object(style_outputs, content_outputs, style_target, content_target):\n",
        "  style_weight = 1e-2\n",
        "  content_weight = 1e-4\n",
        "  content_loss = tf.reduce_mean((content_outputs - content_target)**2)\n",
        "  style_loss = tf.add_n(tf.reduce_mean((output_ - target_)**2) for output_, target_ in zip(style_outputs, style_target))\n",
        "  total_loss = style_weight*style_loss+content_weight*content_loss"
      ],
      "metadata": {
        "id": "FcigcbtmFOWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model = load_vgg()"
      ],
      "metadata": {
        "id": "ErRh3RszFTpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHhxMlAMp9lh"
      },
      "outputs": [],
      "source": [
        "# Instantiate one optimizer for the discriminator and another for the generator.\n",
        "d_optimizer = Adam(learning_rate=0.0003)\n",
        "g_optimizer = Adam(learning_rate=0.0004)\n",
        "\n",
        "# Instantiate a loss function.\n",
        "loss_fn = MeanSquaredError()\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(low, high, for_generator):\n",
        "  \n",
        "    #Select a random half batch of normal light image\n",
        "    # idx = np.random.randint(0, dataH_all.shape[0], int(batch_size/2))\n",
        "    # imgs_N = dataH_all[idx]\n",
        "    idxs = tf.range(tf.shape(high)[0])\n",
        "    ridxs = tf.random.shuffle(idxs)[:high.shape[0]]\n",
        "    imgs_N = tf.gather(high, ridxs)\n",
        "    #Select a random half batch of low light image\n",
        "    # idx = np.random.randint(0, dataL_all.shape[0], int(batch_size/2))\n",
        "    # imgs_L = dataL_all[idx]\n",
        "    idxs = tf.range(tf.shape(low)[0])\n",
        "    ridxs = tf.random.shuffle(idxs)[:low.shape[0]]\n",
        "    imgs_L = tf.gather(low, ridxs)\n",
        "\n",
        "    # Decode them to fake images\n",
        "    generated_images = generator(imgs_L)\n",
        "    # Combine them with real images\n",
        "    combined_images = tf.concat([generated_images, imgs_N], axis=0)\n",
        "\n",
        "    # Assemble labels discriminating real from fake images\n",
        "    # labels = tf.concat(\n",
        "    #     [tf.zeros((generated_images.shape[0], 1)), tf.ones((imgs_N.shape[0], 1))], axis=0\n",
        "    # )\n",
        "    labels = tf.concat(\n",
        "        [tf.zeros((generated_images.shape[0], 1)), tf.ones((imgs_N.shape[0], 1))], axis=0\n",
        "    )\n",
        "    # Add random noise to the labels - important trick!\n",
        "    labels += 0.05 * tf.random.uniform(labels.shape)\n",
        "\n",
        "    # Train the global discriminator\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = discriminator_global(combined_images)\n",
        "        d_loss_global = loss_fn(labels, predictions)\n",
        "    grads = tape.gradient(d_loss_global, discriminator_global.trainable_weights)\n",
        "    d_optimizer.apply_gradients(zip(grads, discriminator_global.trainable_weights))\n",
        "    # Train the local discriminator\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = discriminator_local(combined_images)\n",
        "        d_loss_local = loss_fn(labels, predictions)\n",
        "    grads = tape.gradient(d_loss_local, discriminator_local.trainable_weights)\n",
        "    d_optimizer.apply_gradients(zip(grads, discriminator_local.trainable_weights))\n",
        "\n",
        "    #Select a random half batch of low light image\n",
        "    # idx = np.random.randint(0, dataL_all.shape[0], batch_size)\n",
        "    # imgs_L = dataL_all[idx]\n",
        "    imgs = low\n",
        "    # Assemble labels that say \"all real images\"\n",
        "    misleading_labels = tf.ones((imgs.shape[0], 1))\n",
        "\n",
        "    # Train the generator (note that we should *not* update the weights\n",
        "    # of the discriminator)!\n",
        "    with tf.GradientTape() as tape:\n",
        "        g_img = generator(imgs)\n",
        "        predictions_global = discriminator_global(g_img)\n",
        "        g_loss_global = loss_fn(misleading_labels, predictions_global)\n",
        "        predictions_local = discriminator_global(g_img)\n",
        "        g_loss_local = loss_fn(misleading_labels, predictions_local)\n",
        "        # Content and style loss\n",
        "        output_target = vgg_model(g_img*255)\n",
        "        output_generated = vgg_model(high*255)\n",
        "        content_style_loss = loss_object(output_generated[1], output_generated[0],output_target[1], output_target[0])\n",
        "\n",
        "        g_loss = g_loss_global + g_loss_local + content_style_loss\n",
        "    grads = tape.gradient(g_loss, generator.trainable_weights)\n",
        "    g_optimizer.apply_gradients(zip(grads, generator.trainable_weights))\n",
        "\n",
        "    return d_loss_global, d_loss_local, g_loss,  generated_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dWZetMrnvyf"
      },
      "outputs": [],
      "source": [
        "def train(epochs, save_interval=50):\n",
        "  \n",
        "  print(\"Start training\")\n",
        "  for epoch in range(epochs):\n",
        "    # Train the discriminator & generator on one batch of real images.\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(zip(dataL_all, dataH_all)):\n",
        "      d_loss_global, d_loss_local, g_loss, generated_images = train_step(x_batch_train, y_batch_train, for_generator)\n",
        "      if step % 2 == 0:\n",
        "        # Print metrics\n",
        "        print(\"epoch> %d | step> %d | D global>%.2f | D local>%.2f | G loss>%.2f\" % (epoch,step, d_loss_global, d_loss_local, g_loss))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXBUpS_7ru1A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65452063-92f3-4b5c-a97e-2d6dc68052fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training\n",
            "epoch> 0 | step> 0 | D global>0.53 | D local>0.53 | G loss>1.97\n",
            "epoch> 0 | step> 2 | D global>0.51 | D local>0.52 | G loss>1.90\n",
            "epoch> 0 | step> 4 | D global>0.49 | D local>0.51 | G loss>1.75\n",
            "epoch> 0 | step> 6 | D global>0.76 | D local>0.83 | G loss>0.71\n",
            "epoch> 0 | step> 8 | D global>1.27 | D local>0.49 | G loss>0.01\n",
            "epoch> 0 | step> 10 | D global>1.49 | D local>0.48 | G loss>0.27\n",
            "epoch> 0 | step> 12 | D global>0.44 | D local>0.50 | G loss>23.72\n",
            "epoch> 0 | step> 14 | D global>0.50 | D local>0.45 | G loss>3.03\n",
            "epoch> 0 | step> 16 | D global>0.44 | D local>0.44 | G loss>1.83\n",
            "epoch> 0 | step> 18 | D global>0.43 | D local>0.42 | G loss>1.69\n",
            "epoch> 0 | step> 20 | D global>0.42 | D local>0.41 | G loss>1.57\n",
            "epoch> 0 | step> 22 | D global>0.39 | D local>0.38 | G loss>1.45\n",
            "epoch> 1 | step> 0 | D global>0.37 | D local>0.36 | G loss>1.31\n",
            "epoch> 1 | step> 2 | D global>0.14 | D local>0.14 | G loss>1.17\n",
            "epoch> 1 | step> 4 | D global>0.31 | D local>0.30 | G loss>0.99\n",
            "epoch> 1 | step> 6 | D global>0.28 | D local>0.28 | G loss>0.77\n",
            "epoch> 1 | step> 8 | D global>0.26 | D local>0.25 | G loss>0.56\n",
            "epoch> 1 | step> 10 | D global>0.25 | D local>0.24 | G loss>0.37\n",
            "epoch> 1 | step> 12 | D global>0.26 | D local>0.26 | G loss>0.25\n",
            "epoch> 1 | step> 14 | D global>0.28 | D local>0.28 | G loss>0.20\n",
            "epoch> 1 | step> 16 | D global>0.27 | D local>0.28 | G loss>0.24\n",
            "epoch> 1 | step> 18 | D global>0.26 | D local>0.26 | G loss>0.32\n",
            "epoch> 1 | step> 20 | D global>0.25 | D local>0.24 | G loss>0.42\n",
            "epoch> 1 | step> 22 | D global>0.24 | D local>0.24 | G loss>0.51\n",
            "epoch> 2 | step> 0 | D global>0.25 | D local>0.24 | G loss>0.56\n",
            "epoch> 2 | step> 2 | D global>0.25 | D local>0.24 | G loss>0.59\n",
            "epoch> 2 | step> 4 | D global>0.25 | D local>0.24 | G loss>0.59\n",
            "epoch> 2 | step> 6 | D global>0.26 | D local>0.24 | G loss>0.56\n",
            "epoch> 2 | step> 8 | D global>0.30 | D local>0.27 | G loss>0.56\n",
            "epoch> 2 | step> 10 | D global>0.25 | D local>0.22 | G loss>0.51\n",
            "epoch> 2 | step> 12 | D global>0.25 | D local>0.22 | G loss>0.47\n",
            "epoch> 2 | step> 14 | D global>0.25 | D local>0.21 | G loss>0.43\n",
            "epoch> 2 | step> 16 | D global>0.25 | D local>0.21 | G loss>0.40\n",
            "epoch> 2 | step> 18 | D global>0.25 | D local>0.20 | G loss>0.39\n",
            "epoch> 2 | step> 20 | D global>0.25 | D local>0.22 | G loss>0.40\n",
            "epoch> 2 | step> 22 | D global>0.25 | D local>0.24 | G loss>0.41\n",
            "epoch> 3 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 3 | step> 2 | D global>0.25 | D local>0.27 | G loss>0.45\n",
            "epoch> 3 | step> 4 | D global>0.25 | D local>0.29 | G loss>0.47\n",
            "epoch> 3 | step> 6 | D global>0.25 | D local>0.31 | G loss>0.48\n",
            "epoch> 3 | step> 8 | D global>0.25 | D local>0.32 | G loss>0.42\n",
            "epoch> 3 | step> 10 | D global>0.25 | D local>0.32 | G loss>0.38\n",
            "epoch> 3 | step> 12 | D global>0.25 | D local>0.31 | G loss>0.36\n",
            "epoch> 3 | step> 14 | D global>0.25 | D local>0.30 | G loss>0.37\n",
            "epoch> 3 | step> 16 | D global>0.25 | D local>0.29 | G loss>0.39\n",
            "epoch> 3 | step> 18 | D global>0.25 | D local>0.28 | G loss>0.42\n",
            "epoch> 3 | step> 20 | D global>0.25 | D local>0.22 | G loss>0.49\n",
            "epoch> 3 | step> 22 | D global>0.25 | D local>0.26 | G loss>0.54\n",
            "epoch> 4 | step> 0 | D global>0.26 | D local>0.25 | G loss>0.60\n",
            "epoch> 4 | step> 2 | D global>0.21 | D local>0.18 | G loss>0.63\n",
            "epoch> 4 | step> 4 | D global>0.26 | D local>0.25 | G loss>0.66\n",
            "epoch> 4 | step> 6 | D global>0.26 | D local>0.25 | G loss>0.66\n",
            "epoch> 4 | step> 8 | D global>0.26 | D local>0.25 | G loss>0.62\n",
            "epoch> 4 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.57\n",
            "epoch> 4 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 4 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 4 | step> 16 | D global>0.25 | D local>0.23 | G loss>0.38\n",
            "epoch> 4 | step> 18 | D global>0.25 | D local>0.22 | G loss>0.37\n",
            "epoch> 4 | step> 20 | D global>0.22 | D local>0.19 | G loss>0.34\n",
            "epoch> 4 | step> 22 | D global>0.26 | D local>0.23 | G loss>0.31\n",
            "epoch> 5 | step> 0 | D global>0.20 | D local>0.17 | G loss>0.29\n",
            "epoch> 5 | step> 2 | D global>0.26 | D local>0.24 | G loss>0.28\n",
            "epoch> 5 | step> 4 | D global>0.26 | D local>0.23 | G loss>0.32\n",
            "epoch> 5 | step> 6 | D global>0.25 | D local>0.24 | G loss>0.38\n",
            "epoch> 5 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 5 | step> 10 | D global>0.25 | D local>0.26 | G loss>0.51\n",
            "epoch> 5 | step> 12 | D global>0.25 | D local>0.26 | G loss>0.55\n",
            "epoch> 5 | step> 14 | D global>0.25 | D local>0.26 | G loss>0.56\n",
            "epoch> 5 | step> 16 | D global>0.26 | D local>0.27 | G loss>0.54\n",
            "epoch> 5 | step> 18 | D global>0.25 | D local>0.27 | G loss>0.58\n",
            "epoch> 5 | step> 20 | D global>0.26 | D local>0.28 | G loss>0.58\n",
            "epoch> 5 | step> 22 | D global>0.26 | D local>0.28 | G loss>0.56\n",
            "epoch> 6 | step> 0 | D global>0.26 | D local>0.28 | G loss>0.52\n",
            "epoch> 6 | step> 2 | D global>0.25 | D local>0.28 | G loss>0.47\n",
            "epoch> 6 | step> 4 | D global>0.25 | D local>0.28 | G loss>0.50\n",
            "epoch> 6 | step> 6 | D global>0.25 | D local>0.28 | G loss>0.51\n",
            "epoch> 6 | step> 8 | D global>0.25 | D local>0.28 | G loss>0.51\n",
            "epoch> 6 | step> 10 | D global>0.26 | D local>0.28 | G loss>0.50\n",
            "epoch> 6 | step> 12 | D global>0.25 | D local>0.28 | G loss>0.48\n",
            "epoch> 6 | step> 14 | D global>0.25 | D local>0.28 | G loss>0.40\n",
            "epoch> 6 | step> 16 | D global>0.25 | D local>0.27 | G loss>0.35\n",
            "epoch> 6 | step> 18 | D global>0.25 | D local>0.28 | G loss>0.34\n",
            "epoch> 6 | step> 20 | D global>0.25 | D local>0.27 | G loss>0.35\n",
            "epoch> 6 | step> 22 | D global>0.25 | D local>0.27 | G loss>0.39\n",
            "epoch> 7 | step> 0 | D global>0.24 | D local>0.26 | G loss>0.44\n",
            "epoch> 7 | step> 2 | D global>0.24 | D local>0.26 | G loss>0.48\n",
            "epoch> 7 | step> 4 | D global>0.25 | D local>0.26 | G loss>0.51\n",
            "epoch> 7 | step> 6 | D global>0.25 | D local>0.26 | G loss>0.52\n",
            "epoch> 7 | step> 8 | D global>0.26 | D local>0.27 | G loss>0.48\n",
            "epoch> 7 | step> 10 | D global>0.24 | D local>0.25 | G loss>0.41\n",
            "epoch> 7 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.37\n",
            "epoch> 7 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.35\n",
            "epoch> 7 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.36\n",
            "epoch> 7 | step> 18 | D global>0.29 | D local>0.27 | G loss>0.42\n",
            "epoch> 7 | step> 20 | D global>0.26 | D local>0.25 | G loss>0.52\n",
            "epoch> 7 | step> 22 | D global>0.26 | D local>0.24 | G loss>0.59\n",
            "epoch> 8 | step> 0 | D global>0.26 | D local>0.24 | G loss>0.63\n",
            "epoch> 8 | step> 2 | D global>0.26 | D local>0.24 | G loss>0.58\n",
            "epoch> 8 | step> 4 | D global>0.26 | D local>0.24 | G loss>0.51\n",
            "epoch> 8 | step> 6 | D global>0.26 | D local>0.24 | G loss>0.43\n",
            "epoch> 8 | step> 8 | D global>0.26 | D local>0.24 | G loss>0.39\n",
            "epoch> 8 | step> 10 | D global>0.26 | D local>0.24 | G loss>0.37\n",
            "epoch> 8 | step> 12 | D global>0.26 | D local>0.23 | G loss>0.38\n",
            "epoch> 8 | step> 14 | D global>0.25 | D local>0.23 | G loss>0.41\n",
            "epoch> 8 | step> 16 | D global>0.25 | D local>0.22 | G loss>0.44\n",
            "epoch> 8 | step> 18 | D global>0.25 | D local>0.24 | G loss>0.51\n",
            "epoch> 8 | step> 20 | D global>0.25 | D local>0.21 | G loss>0.58\n",
            "epoch> 8 | step> 22 | D global>0.25 | D local>0.20 | G loss>0.63\n",
            "epoch> 9 | step> 0 | D global>0.25 | D local>0.20 | G loss>0.64\n",
            "epoch> 9 | step> 2 | D global>0.25 | D local>0.18 | G loss>0.62\n",
            "epoch> 9 | step> 4 | D global>0.24 | D local>0.17 | G loss>0.57\n",
            "epoch> 9 | step> 6 | D global>0.24 | D local>0.14 | G loss>0.52\n",
            "epoch> 9 | step> 8 | D global>0.24 | D local>0.12 | G loss>0.46\n",
            "epoch> 9 | step> 10 | D global>0.24 | D local>0.10 | G loss>0.42\n",
            "epoch> 9 | step> 12 | D global>0.24 | D local>0.08 | G loss>0.40\n",
            "epoch> 9 | step> 14 | D global>0.24 | D local>0.05 | G loss>0.41\n",
            "epoch> 9 | step> 16 | D global>0.22 | D local>0.02 | G loss>0.39\n",
            "epoch> 9 | step> 18 | D global>0.24 | D local>0.04 | G loss>0.44\n",
            "epoch> 9 | step> 20 | D global>0.24 | D local>0.07 | G loss>0.49\n",
            "epoch> 9 | step> 22 | D global>0.25 | D local>0.13 | G loss>0.53\n",
            "epoch> 10 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.54\n",
            "epoch> 10 | step> 2 | D global>0.25 | D local>0.61 | G loss>0.52\n",
            "epoch> 10 | step> 4 | D global>0.26 | D local>0.85 | G loss>0.50\n",
            "epoch> 10 | step> 6 | D global>0.28 | D local>0.79 | G loss>0.43\n",
            "epoch> 10 | step> 8 | D global>0.26 | D local>0.46 | G loss>0.34\n",
            "epoch> 10 | step> 10 | D global>0.27 | D local>0.41 | G loss>0.31\n",
            "epoch> 10 | step> 12 | D global>0.27 | D local>0.39 | G loss>0.31\n",
            "epoch> 10 | step> 14 | D global>0.27 | D local>0.38 | G loss>0.36\n",
            "epoch> 10 | step> 16 | D global>0.28 | D local>0.14 | G loss>0.46\n",
            "epoch> 10 | step> 18 | D global>0.26 | D local>0.34 | G loss>0.58\n",
            "epoch> 10 | step> 20 | D global>0.25 | D local>0.32 | G loss>0.65\n",
            "epoch> 10 | step> 22 | D global>0.25 | D local>0.30 | G loss>0.66\n",
            "epoch> 11 | step> 0 | D global>0.24 | D local>0.28 | G loss>0.63\n",
            "epoch> 11 | step> 2 | D global>0.23 | D local>0.25 | G loss>0.58\n",
            "epoch> 11 | step> 4 | D global>0.22 | D local>0.23 | G loss>0.52\n",
            "epoch> 11 | step> 6 | D global>0.21 | D local>0.21 | G loss>0.45\n",
            "epoch> 11 | step> 8 | D global>0.24 | D local>0.26 | G loss>0.29\n",
            "epoch> 11 | step> 10 | D global>0.26 | D local>0.34 | G loss>0.24\n",
            "epoch> 11 | step> 12 | D global>0.26 | D local>0.48 | G loss>0.33\n",
            "epoch> 11 | step> 14 | D global>0.27 | D local>0.45 | G loss>0.47\n",
            "epoch> 11 | step> 16 | D global>0.22 | D local>0.32 | G loss>0.83\n",
            "epoch> 11 | step> 18 | D global>0.20 | D local>0.28 | G loss>0.94\n",
            "epoch> 11 | step> 20 | D global>0.21 | D local>0.29 | G loss>0.62\n",
            "epoch> 11 | step> 22 | D global>0.23 | D local>0.30 | G loss>0.54\n",
            "epoch> 12 | step> 0 | D global>0.24 | D local>0.30 | G loss>0.53\n",
            "epoch> 12 | step> 2 | D global>0.25 | D local>0.30 | G loss>0.49\n",
            "epoch> 12 | step> 4 | D global>0.26 | D local>0.30 | G loss>0.47\n",
            "epoch> 12 | step> 6 | D global>0.26 | D local>0.30 | G loss>0.45\n",
            "epoch> 12 | step> 8 | D global>0.24 | D local>0.29 | G loss>0.48\n",
            "epoch> 12 | step> 10 | D global>0.24 | D local>0.28 | G loss>0.35\n",
            "epoch> 12 | step> 12 | D global>0.20 | D local>0.28 | G loss>0.48\n",
            "epoch> 12 | step> 14 | D global>0.22 | D local>0.27 | G loss>0.50\n",
            "epoch> 12 | step> 16 | D global>0.22 | D local>0.18 | G loss>0.77\n",
            "epoch> 12 | step> 18 | D global>0.27 | D local>0.27 | G loss>0.90\n",
            "epoch> 12 | step> 20 | D global>0.28 | D local>0.26 | G loss>0.70\n",
            "epoch> 12 | step> 22 | D global>0.24 | D local>0.26 | G loss>0.40\n",
            "epoch> 13 | step> 0 | D global>0.26 | D local>0.26 | G loss>0.23\n",
            "epoch> 13 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.32\n",
            "epoch> 13 | step> 4 | D global>0.25 | D local>0.26 | G loss>0.49\n",
            "epoch> 13 | step> 6 | D global>0.26 | D local>0.25 | G loss>0.61\n",
            "epoch> 13 | step> 8 | D global>0.27 | D local>0.25 | G loss>0.66\n",
            "epoch> 13 | step> 10 | D global>0.28 | D local>0.24 | G loss>0.53\n",
            "epoch> 13 | step> 12 | D global>0.28 | D local>0.24 | G loss>0.44\n",
            "epoch> 13 | step> 14 | D global>0.27 | D local>0.25 | G loss>0.41\n",
            "epoch> 13 | step> 16 | D global>0.25 | D local>0.24 | G loss>0.55\n",
            "epoch> 13 | step> 18 | D global>0.25 | D local>0.24 | G loss>0.63\n",
            "epoch> 13 | step> 20 | D global>0.25 | D local>0.24 | G loss>0.63\n",
            "epoch> 13 | step> 22 | D global>0.24 | D local>0.24 | G loss>0.58\n",
            "epoch> 14 | step> 0 | D global>0.24 | D local>0.24 | G loss>0.40\n",
            "epoch> 14 | step> 2 | D global>0.24 | D local>0.24 | G loss>0.30\n",
            "epoch> 14 | step> 4 | D global>0.25 | D local>0.24 | G loss>0.28\n",
            "epoch> 14 | step> 6 | D global>0.19 | D local>0.22 | G loss>0.28\n",
            "epoch> 14 | step> 8 | D global>0.26 | D local>0.23 | G loss>0.28\n",
            "epoch> 14 | step> 10 | D global>0.25 | D local>0.23 | G loss>0.38\n",
            "epoch> 14 | step> 12 | D global>0.25 | D local>0.24 | G loss>0.48\n",
            "epoch> 14 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.54\n",
            "epoch> 14 | step> 16 | D global>0.26 | D local>0.25 | G loss>0.67\n",
            "epoch> 14 | step> 18 | D global>0.27 | D local>0.27 | G loss>0.70\n",
            "epoch> 14 | step> 20 | D global>0.27 | D local>0.28 | G loss>0.66\n",
            "epoch> 14 | step> 22 | D global>0.27 | D local>0.30 | G loss>0.60\n",
            "epoch> 15 | step> 0 | D global>0.26 | D local>0.29 | G loss>0.52\n",
            "epoch> 15 | step> 2 | D global>0.25 | D local>0.28 | G loss>0.42\n",
            "epoch> 15 | step> 4 | D global>0.25 | D local>0.27 | G loss>0.36\n",
            "epoch> 15 | step> 6 | D global>0.25 | D local>0.26 | G loss>0.35\n",
            "epoch> 15 | step> 8 | D global>0.25 | D local>0.26 | G loss>0.37\n",
            "epoch> 15 | step> 10 | D global>0.25 | D local>0.26 | G loss>0.42\n",
            "epoch> 15 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 15 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 15 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 15 | step> 18 | D global>0.29 | D local>0.28 | G loss>0.54\n",
            "epoch> 15 | step> 20 | D global>0.26 | D local>0.25 | G loss>0.52\n",
            "epoch> 15 | step> 22 | D global>0.26 | D local>0.24 | G loss>0.49\n",
            "epoch> 16 | step> 0 | D global>0.26 | D local>0.24 | G loss>0.45\n",
            "epoch> 16 | step> 2 | D global>0.26 | D local>0.24 | G loss>0.42\n",
            "epoch> 16 | step> 4 | D global>0.26 | D local>0.24 | G loss>0.40\n",
            "epoch> 16 | step> 6 | D global>0.26 | D local>0.25 | G loss>0.40\n",
            "epoch> 16 | step> 8 | D global>0.26 | D local>0.25 | G loss>0.42\n",
            "epoch> 16 | step> 10 | D global>0.26 | D local>0.25 | G loss>0.52\n",
            "epoch> 16 | step> 12 | D global>0.26 | D local>0.25 | G loss>0.59\n",
            "epoch> 16 | step> 14 | D global>0.26 | D local>0.25 | G loss>0.62\n",
            "epoch> 16 | step> 16 | D global>0.32 | D local>0.25 | G loss>0.58\n",
            "epoch> 16 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 16 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 16 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 17 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.36\n",
            "epoch> 17 | step> 2 | D global>0.24 | D local>0.24 | G loss>0.37\n",
            "epoch> 17 | step> 4 | D global>0.27 | D local>0.26 | G loss>0.43\n",
            "epoch> 17 | step> 6 | D global>0.24 | D local>0.25 | G loss>0.52\n",
            "epoch> 17 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.58\n",
            "epoch> 17 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.60\n",
            "epoch> 17 | step> 12 | D global>0.26 | D local>0.25 | G loss>0.60\n",
            "epoch> 17 | step> 14 | D global>0.30 | D local>0.25 | G loss>0.54\n",
            "epoch> 17 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 17 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 17 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.34\n",
            "epoch> 17 | step> 22 | D global>0.26 | D local>0.26 | G loss>0.33\n",
            "epoch> 18 | step> 0 | D global>0.30 | D local>0.25 | G loss>0.38\n",
            "epoch> 18 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 18 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.54\n",
            "epoch> 18 | step> 6 | D global>0.26 | D local>0.25 | G loss>0.59\n",
            "epoch> 18 | step> 8 | D global>0.26 | D local>0.25 | G loss>0.60\n",
            "epoch> 18 | step> 10 | D global>0.26 | D local>0.26 | G loss>0.54\n",
            "epoch> 18 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 18 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 18 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 18 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.37\n",
            "epoch> 18 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.37\n",
            "epoch> 18 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 19 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 19 | step> 2 | D global>0.23 | D local>0.25 | G loss>0.40\n",
            "epoch> 19 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 19 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 19 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 19 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 19 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 19 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 19 | step> 16 | D global>0.25 | D local>0.26 | G loss>0.50\n",
            "epoch> 19 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.56\n",
            "epoch> 19 | step> 20 | D global>0.26 | D local>0.25 | G loss>0.59\n",
            "epoch> 19 | step> 22 | D global>0.26 | D local>0.25 | G loss>0.59\n",
            "epoch> 20 | step> 0 | D global>0.26 | D local>0.25 | G loss>0.58\n",
            "epoch> 20 | step> 2 | D global>0.30 | D local>0.26 | G loss>0.53\n",
            "epoch> 20 | step> 4 | D global>0.26 | D local>0.25 | G loss>0.45\n",
            "epoch> 20 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 20 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.35\n",
            "epoch> 20 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.34\n",
            "epoch> 20 | step> 12 | D global>0.26 | D local>0.25 | G loss>0.35\n",
            "epoch> 20 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 20 | step> 16 | D global>0.25 | D local>0.24 | G loss>0.42\n",
            "epoch> 20 | step> 18 | D global>0.25 | D local>0.24 | G loss>0.45\n",
            "epoch> 20 | step> 20 | D global>0.25 | D local>0.24 | G loss>0.53\n",
            "epoch> 20 | step> 22 | D global>0.25 | D local>0.24 | G loss>0.58\n",
            "epoch> 21 | step> 0 | D global>0.25 | D local>0.24 | G loss>0.61\n",
            "epoch> 21 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.61\n",
            "epoch> 21 | step> 4 | D global>0.30 | D local>0.25 | G loss>0.57\n",
            "epoch> 21 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 21 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 21 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 21 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.37\n",
            "epoch> 21 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.36\n",
            "epoch> 21 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.37\n",
            "epoch> 21 | step> 18 | D global>0.28 | D local>0.26 | G loss>0.42\n",
            "epoch> 21 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 21 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.54\n",
            "epoch> 22 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.57\n",
            "epoch> 22 | step> 2 | D global>0.26 | D local>0.25 | G loss>0.58\n",
            "epoch> 22 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.57\n",
            "epoch> 22 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.55\n",
            "epoch> 22 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 22 | step> 10 | D global>0.26 | D local>0.26 | G loss>0.49\n",
            "epoch> 22 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 22 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 22 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 22 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 22 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 22 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 23 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 23 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 23 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 23 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 23 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 23 | step> 10 | D global>0.26 | D local>0.25 | G loss>0.48\n",
            "epoch> 23 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 23 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 23 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 23 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 23 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 23 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 24 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 24 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 24 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 24 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.37\n",
            "epoch> 24 | step> 8 | D global>0.26 | D local>0.25 | G loss>0.37\n",
            "epoch> 24 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 24 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 24 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 24 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.55\n",
            "epoch> 24 | step> 18 | D global>0.25 | D local>0.24 | G loss>0.57\n",
            "epoch> 24 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.57\n",
            "epoch> 24 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.56\n",
            "epoch> 25 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.54\n",
            "epoch> 25 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 25 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 25 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 25 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 25 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 25 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 25 | step> 14 | D global>0.27 | D local>0.25 | G loss>0.39\n",
            "epoch> 25 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 25 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 25 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 25 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 26 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 26 | step> 2 | D global>0.26 | D local>0.25 | G loss>0.46\n",
            "epoch> 26 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 26 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 26 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 26 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 26 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 26 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 26 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 26 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 26 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.53\n",
            "epoch> 26 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.56\n",
            "epoch> 27 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.57\n",
            "epoch> 27 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.56\n",
            "epoch> 27 | step> 4 | D global>0.29 | D local>0.26 | G loss>0.53\n",
            "epoch> 27 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 27 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 27 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 27 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 27 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 27 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 27 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 27 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 27 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 28 | step> 0 | D global>0.26 | D local>0.24 | G loss>0.45\n",
            "epoch> 28 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 28 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 28 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.54\n",
            "epoch> 28 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.54\n",
            "epoch> 28 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.54\n",
            "epoch> 28 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 28 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 28 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 28 | step> 18 | D global>0.26 | D local>0.25 | G loss>0.44\n",
            "epoch> 28 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 28 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.36\n",
            "epoch> 29 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.35\n",
            "epoch> 29 | step> 2 | D global>0.26 | D local>0.25 | G loss>0.31\n",
            "epoch> 29 | step> 4 | D global>0.26 | D local>0.25 | G loss>0.31\n",
            "epoch> 29 | step> 6 | D global>0.26 | D local>0.25 | G loss>0.32\n",
            "epoch> 29 | step> 8 | D global>0.26 | D local>0.25 | G loss>0.35\n",
            "epoch> 29 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 29 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 29 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 29 | step> 16 | D global>0.24 | D local>0.27 | G loss>0.51\n",
            "epoch> 29 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.56\n",
            "epoch> 29 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.59\n",
            "epoch> 29 | step> 22 | D global>0.26 | D local>0.25 | G loss>0.60\n",
            "epoch> 30 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.59\n",
            "epoch> 30 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.57\n",
            "epoch> 30 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.55\n",
            "epoch> 30 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 30 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 30 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 30 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 30 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 30 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.35\n",
            "epoch> 30 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.34\n",
            "epoch> 30 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.34\n",
            "epoch> 30 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 31 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 31 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 31 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 31 | step> 6 | D global>0.25 | D local>0.26 | G loss>0.54\n",
            "epoch> 31 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 31 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 31 | step> 12 | D global>0.25 | D local>0.26 | G loss>0.46\n",
            "epoch> 31 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 31 | step> 16 | D global>0.26 | D local>0.26 | G loss>0.44\n",
            "epoch> 31 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 31 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 31 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 32 | step> 0 | D global>0.24 | D local>0.25 | G loss>0.50\n",
            "epoch> 32 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.53\n",
            "epoch> 32 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.54\n",
            "epoch> 32 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 32 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 32 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 32 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 32 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 32 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 32 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 32 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 32 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 33 | step> 0 | D global>0.24 | D local>0.25 | G loss>0.41\n",
            "epoch> 33 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 33 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 33 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 33 | step> 8 | D global>0.27 | D local>0.26 | G loss>0.41\n",
            "epoch> 33 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 33 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 33 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 33 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.53\n",
            "epoch> 33 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.53\n",
            "epoch> 33 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.53\n",
            "epoch> 33 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 34 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 34 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 34 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 34 | step> 6 | D global>0.25 | D local>0.24 | G loss>0.47\n",
            "epoch> 34 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 34 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 34 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 34 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 34 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 34 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 34 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 34 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 35 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 35 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 35 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 35 | step> 6 | D global>0.24 | D local>0.25 | G loss>0.40\n",
            "epoch> 35 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 35 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 35 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 35 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 35 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 35 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 35 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 35 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 36 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.53\n",
            "epoch> 36 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.55\n",
            "epoch> 36 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.56\n",
            "epoch> 36 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.55\n",
            "epoch> 36 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.57\n",
            "epoch> 36 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.57\n",
            "epoch> 36 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.56\n",
            "epoch> 36 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.54\n",
            "epoch> 36 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 36 | step> 18 | D global>0.27 | D local>0.28 | G loss>0.48\n",
            "epoch> 36 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 36 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 37 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.37\n",
            "epoch> 37 | step> 2 | D global>0.22 | D local>0.26 | G loss>0.34\n",
            "epoch> 37 | step> 4 | D global>0.26 | D local>0.25 | G loss>0.31\n",
            "epoch> 37 | step> 6 | D global>0.26 | D local>0.25 | G loss>0.31\n",
            "epoch> 37 | step> 8 | D global>0.26 | D local>0.25 | G loss>0.32\n",
            "epoch> 37 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.35\n",
            "epoch> 37 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 37 | step> 14 | D global>0.27 | D local>0.27 | G loss>0.43\n",
            "epoch> 37 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 37 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.54\n",
            "epoch> 37 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.56\n",
            "epoch> 37 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.58\n",
            "epoch> 38 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.58\n",
            "epoch> 38 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.57\n",
            "epoch> 38 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.57\n",
            "epoch> 38 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.57\n",
            "epoch> 38 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.56\n",
            "epoch> 38 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.54\n",
            "epoch> 38 | step> 12 | D global>0.28 | D local>0.27 | G loss>0.50\n",
            "epoch> 38 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 38 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 38 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 38 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 38 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.37\n",
            "epoch> 39 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 39 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 39 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 39 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 39 | step> 8 | D global>0.24 | D local>0.24 | G loss>0.42\n",
            "epoch> 39 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 39 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 39 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 39 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 39 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 39 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 39 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 40 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 40 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 40 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 40 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 40 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 40 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 40 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 40 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 40 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 40 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 40 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 40 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 41 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 41 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 41 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 41 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 41 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 41 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 41 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 41 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 41 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 41 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 41 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 41 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 42 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 42 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 42 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 42 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 42 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 42 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 42 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 42 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 42 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 42 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 42 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 42 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 43 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 43 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 43 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 43 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 43 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 43 | step> 10 | D global>0.26 | D local>0.25 | G loss>0.42\n",
            "epoch> 43 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 43 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 43 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 43 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 43 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 43 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 44 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 44 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 44 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 44 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 44 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 44 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 44 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 44 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 44 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 44 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 44 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 44 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 45 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 45 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 45 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 45 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 45 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 45 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 45 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 45 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 45 | step> 16 | D global>0.25 | D local>0.26 | G loss>0.46\n",
            "epoch> 45 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 45 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 45 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 46 | step> 0 | D global>0.23 | D local>0.24 | G loss>0.54\n",
            "epoch> 46 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.56\n",
            "epoch> 46 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.56\n",
            "epoch> 46 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.56\n",
            "epoch> 46 | step> 8 | D global>0.29 | D local>0.27 | G loss>0.54\n",
            "epoch> 46 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 46 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 46 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 46 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 46 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 46 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 46 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 47 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 47 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 47 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 47 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 47 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 47 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 47 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 47 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 47 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 47 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 47 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 47 | step> 22 | D global>0.25 | D local>0.26 | G loss>0.46\n",
            "epoch> 48 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 48 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 48 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.53\n",
            "epoch> 48 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 48 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 48 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 48 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 48 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 48 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 48 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 48 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 48 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 49 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 49 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 49 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 49 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 49 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 49 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 49 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 49 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 49 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 49 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 49 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 49 | step> 22 | D global>0.25 | D local>0.24 | G loss>0.47\n",
            "epoch> 50 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 50 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 50 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 50 | step> 6 | D global>0.24 | D local>0.25 | G loss>0.42\n",
            "epoch> 50 | step> 8 | D global>0.27 | D local>0.25 | G loss>0.41\n",
            "epoch> 50 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 50 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 50 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 50 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 50 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 50 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 50 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 51 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 51 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 51 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 51 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 51 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 51 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 51 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 51 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 51 | step> 16 | D global>0.26 | D local>0.26 | G loss>0.42\n",
            "epoch> 51 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 51 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 51 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 52 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 52 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 52 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 52 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 52 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 52 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 52 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.53\n",
            "epoch> 52 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.53\n",
            "epoch> 52 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 52 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 52 | step> 20 | D global>0.27 | D local>0.26 | G loss>0.48\n",
            "epoch> 52 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 53 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 53 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 53 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 53 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 53 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 53 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 53 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 53 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 53 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 53 | step> 18 | D global>0.24 | D local>0.24 | G loss>0.46\n",
            "epoch> 53 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 53 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 54 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 54 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 54 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 54 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 54 | step> 8 | D global>0.26 | D local>0.25 | G loss>0.45\n",
            "epoch> 54 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 54 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 54 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 54 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 54 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 54 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 54 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 55 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 55 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 55 | step> 4 | D global>0.26 | D local>0.26 | G loss>0.49\n",
            "epoch> 55 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 55 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 55 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.53\n",
            "epoch> 55 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 55 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 55 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 55 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 55 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 55 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 56 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 56 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 56 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 56 | step> 6 | D global>0.23 | D local>0.25 | G loss>0.41\n",
            "epoch> 56 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 56 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 56 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 56 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 56 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 56 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 56 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 56 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 57 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 57 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 57 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 57 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 57 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 57 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 57 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 57 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 57 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 57 | step> 18 | D global>0.27 | D local>0.26 | G loss>0.42\n",
            "epoch> 57 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 57 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 58 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 58 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 58 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 58 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 58 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 58 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.53\n",
            "epoch> 58 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.54\n",
            "epoch> 58 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.53\n",
            "epoch> 58 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.53\n",
            "epoch> 58 | step> 18 | D global>0.28 | D local>0.27 | G loss>0.50\n",
            "epoch> 58 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 58 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 59 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 59 | step> 2 | D global>0.23 | D local>0.25 | G loss>0.38\n",
            "epoch> 59 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.35\n",
            "epoch> 59 | step> 6 | D global>0.26 | D local>0.25 | G loss>0.34\n",
            "epoch> 59 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.36\n",
            "epoch> 59 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 59 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 59 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 59 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 59 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 59 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 59 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 60 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 60 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 60 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 60 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 60 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 60 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 60 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 60 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 60 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 60 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 60 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 60 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 61 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 61 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 61 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 61 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 61 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 61 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 61 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 61 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 61 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 61 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 61 | step> 20 | D global>0.25 | D local>0.26 | G loss>0.44\n",
            "epoch> 61 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 62 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 62 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 62 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 62 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 62 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 62 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 62 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 62 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 62 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 62 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 62 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 62 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 63 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 63 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 63 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 63 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 63 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 63 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 63 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 63 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 63 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 63 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 63 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 63 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 64 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 64 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 64 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 64 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 64 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 64 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 64 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 64 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 64 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 64 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 64 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 64 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 65 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 65 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 65 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 65 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 65 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 65 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 65 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 65 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 65 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 65 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 65 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 65 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 66 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 66 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 66 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 66 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 66 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 66 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 66 | step> 12 | D global>0.27 | D local>0.26 | G loss>0.41\n",
            "epoch> 66 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 66 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 66 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 66 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 66 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 67 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 67 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 67 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 67 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 67 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 67 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 67 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 67 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 67 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 67 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 67 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 67 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 68 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 68 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 68 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 68 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 68 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 68 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 68 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 68 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 68 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 68 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 68 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 68 | step> 22 | D global>0.26 | D local>0.25 | G loss>0.47\n",
            "epoch> 69 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 69 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 69 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 69 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 69 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 69 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 69 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 69 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 69 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 69 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 69 | step> 20 | D global>0.26 | D local>0.25 | G loss>0.49\n",
            "epoch> 69 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 70 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 70 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 70 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 70 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 70 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 70 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 70 | step> 12 | D global>0.26 | D local>0.25 | G loss>0.45\n",
            "epoch> 70 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 70 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 70 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 70 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 70 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 71 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 71 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 71 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 71 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 71 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 71 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 71 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 71 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 71 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 71 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 71 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 71 | step> 22 | D global>0.27 | D local>0.26 | G loss>0.49\n",
            "epoch> 72 | step> 0 | D global>0.24 | D local>0.24 | G loss>0.48\n",
            "epoch> 72 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 72 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 72 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 72 | step> 8 | D global>0.26 | D local>0.26 | G loss>0.46\n",
            "epoch> 72 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 72 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 72 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 72 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 72 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 72 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 72 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 73 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 73 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 73 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 73 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 73 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 73 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 73 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 73 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 73 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 73 | step> 18 | D global>0.26 | D local>0.25 | G loss>0.46\n",
            "epoch> 73 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 73 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 74 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 74 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 74 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 74 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 74 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 74 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 74 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 74 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 74 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 74 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 74 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 74 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 75 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 75 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 75 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 75 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 75 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 75 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 75 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 75 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 75 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 75 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 75 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 75 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 76 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 76 | step> 2 | D global>0.24 | D local>0.25 | G loss>0.42\n",
            "epoch> 76 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 76 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 76 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 76 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 76 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 76 | step> 14 | D global>0.27 | D local>0.26 | G loss>0.42\n",
            "epoch> 76 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 76 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 76 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 76 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 77 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.53\n",
            "epoch> 77 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 77 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 77 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 77 | step> 8 | D global>0.24 | D local>0.24 | G loss>0.50\n",
            "epoch> 77 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 77 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 77 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 77 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 77 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 77 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 77 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 78 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 78 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 78 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 78 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 78 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 78 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 78 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 78 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 78 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 78 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 78 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 78 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 79 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 79 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 79 | step> 4 | D global>0.26 | D local>0.26 | G loss>0.43\n",
            "epoch> 79 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 79 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 79 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 79 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 79 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.50\n",
            "epoch> 79 | step> 16 | D global>0.27 | D local>0.26 | G loss>0.49\n",
            "epoch> 79 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 79 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 79 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.42\n",
            "epoch> 80 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 80 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 80 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 80 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 80 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 80 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 80 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 80 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 80 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 80 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.48\n",
            "epoch> 80 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 80 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.46\n",
            "epoch> 81 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.43\n",
            "epoch> 81 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.41\n",
            "epoch> 81 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 81 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 81 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 81 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 81 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.40\n",
            "epoch> 81 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.39\n",
            "epoch> 81 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 81 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.38\n",
            "epoch> 81 | step> 20 | D global>0.28 | D local>0.27 | G loss>0.41\n",
            "epoch> 81 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 82 | step> 0 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 82 | step> 2 | D global>0.25 | D local>0.25 | G loss>0.52\n",
            "epoch> 82 | step> 4 | D global>0.25 | D local>0.25 | G loss>0.55\n",
            "epoch> 82 | step> 6 | D global>0.25 | D local>0.25 | G loss>0.57\n",
            "epoch> 82 | step> 8 | D global>0.25 | D local>0.25 | G loss>0.55\n",
            "epoch> 82 | step> 10 | D global>0.25 | D local>0.25 | G loss>0.53\n",
            "epoch> 82 | step> 12 | D global>0.25 | D local>0.25 | G loss>0.51\n",
            "epoch> 82 | step> 14 | D global>0.25 | D local>0.25 | G loss>0.49\n",
            "epoch> 82 | step> 16 | D global>0.25 | D local>0.25 | G loss>0.47\n",
            "epoch> 82 | step> 18 | D global>0.25 | D local>0.25 | G loss>0.45\n",
            "epoch> 82 | step> 20 | D global>0.25 | D local>0.25 | G loss>0.44\n",
            "epoch> 82 | step> 22 | D global>0.25 | D local>0.25 | G loss>0.43\n"
          ]
        }
      ],
      "source": [
        "train(epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjjIVKqxr3ao"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/DATA/eval15/\"\n",
        "# load dataset (low light image) - Monet paintings\n",
        "evalH_all = load_images(path + 'high/')\n",
        "evalH_all  = evalH_all .astype('float32') / 255.\n",
        "print('Loaded dataH: ', dataH_all.shape)\n",
        "# load dataset (low light image) - Monet paintings\n",
        "evalL_all  = load_images(path + 'low/')\n",
        "evalL_all  = evalL_all .astype('float32') / 255.\n",
        "print('Loaded dataL: ', dataL_all.shape)\n",
        "generator.evaluate(evalL_all, evalH_all)\n",
        "\n",
        "generator.save('/content/drive/MyDrive/Colab Notebooks/MAGAN-F-200.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fam2L3uYdNj-"
      },
      "outputs": [],
      "source": [
        "# from keras.models import load_model\n",
        "# from numpy.random import randn\n",
        "# model2 = load_model('/content/drive/MyDrive/Colab Notebooks/lle_autoencoder200.h5') #Model trained for 100 epochs\n",
        "\n",
        "path = '/content/drive/MyDrive/DATA/test/'\n",
        "# load dataset (low light image)\n",
        "x_test = load_images(path + 'low/')\n",
        "\n",
        "results_img = generator.predict(x_test)\n",
        "results_img.shape\n",
        "\n",
        "# create figure\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "plt.axis(\"off\")\n",
        "# Adds a subplot at the 1st position\n",
        "fig.add_subplot(2, 3, 1)\n",
        "# showing image\n",
        "plt.imshow(x_test[0])\n",
        "fig.add_subplot(2, 3, 2)\n",
        "# showing image\n",
        "plt.imshow(x_test[1])\n",
        "fig.add_subplot(2, 3, 3)\n",
        "# showing image\n",
        "plt.imshow(x_test[2])\n",
        "\n",
        "fig.add_subplot(2, 3, 4)\n",
        "# showing image\n",
        "plt.imshow(results_img[0])\n",
        "fig.add_subplot(2, 3, 5)\n",
        "# showing image\n",
        "plt.imshow(results_img[1])\n",
        "fig.add_subplot(2, 3, 6)\n",
        "# showing image\n",
        "plt.imshow(results_img[2])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkRzN1pXfkFv"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MAGAN-F.ipynb",
      "provenance": [],
      "mount_file_id": "16U3kTzmteskAY3ZePVgY5pdsoWik260-",
      "authorship_tag": "ABX9TyNwIFHo2+Xae7NszjAmaODK",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}